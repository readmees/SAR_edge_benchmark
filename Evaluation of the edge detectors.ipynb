{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d074f7",
   "metadata": {},
   "source": [
    "# Evaluation of edge detectors\n",
    "This Jupyter Notebook contains the code to generate ROC auc and other metrics based on confusion matrices. The confusion matrices can be created by comparing (in our case 21 thresholds) thresholded binary edge maps with the ground truths created by the Github repository in the README.md. The confusion matrices should be saved in a .csv file named \n",
    "\\[algorithm name\\]_measures.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3842597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from scipy.integrate import simps\n",
    "import scipy\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# np.sqrt has limitations, therefore we use the sqrt from the math library\n",
    "from math import sqrt\n",
    "\n",
    "# For the qualitative evaluation\n",
    "from skimage.filters import farid, roberts, sobel, scharr, prewitt\n",
    "from edge_detectors import frei, laplacianofgausian, wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "048cf76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_conf_matrix(x):\n",
    "    ''' Converst a confusion matrix save in string to a dictornary and returns the\n",
    "        true positives, true negatives, false negative and false postiives\n",
    "    '''\n",
    "    x = ast.literal_eval(x) # The dicts are saves as strings, so need to be converted \n",
    "    return x['tn'], x['fp'], x['fn'], x['tp']\n",
    "\n",
    "\n",
    "# The following formulas are taken from https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "def TPR(x):\n",
    "    TN, FP, FN, TP = extract_conf_matrix(x)\n",
    "    if TP+FN == 0:\n",
    "        return 0\n",
    "    return TP/(TP+FN)\n",
    "    \n",
    "def TNR(x):\n",
    "    TN, FP, FN, TP = extract_conf_matrix(x)\n",
    "    if TN+FP == 0:\n",
    "        return 0\n",
    "    return TN/(TN+FP)\n",
    "\n",
    "def PPV(x):\n",
    "    TN, FP, FN, TP = extract_conf_matrix(x)\n",
    "    if TP+FP == 0:\n",
    "        return 0\n",
    "    return TP/(TP+FP)\n",
    "\n",
    "def NPV(x):\n",
    "    TN, FP, FN, TP = extract_conf_matrix(x)\n",
    "    if TN+FN == 0:\n",
    "        return 0\n",
    "    return TN/(TN+FN)\n",
    "\n",
    "def FNR(x):\n",
    "    return 1 - TPR(x)\n",
    "\n",
    "def FPR(x):\n",
    "    '''fall-out or false positive rate (FPR)'''\n",
    "    return 1 - TNR(x)\n",
    "\n",
    "def FDR(x):\n",
    "    return 1 - PPV(x)\n",
    "\n",
    "def FOR(x):\n",
    "    return 1 - NPV(x)\n",
    "\n",
    "def PT(x):\n",
    "    t = sqrt(TPR(x)*(-TNR(x)+1))+TNR(x)-1\n",
    "    n = TPR(x)+TNR(x)-1\n",
    "    return t/n\n",
    "\n",
    "def TS(x):\n",
    "    TN, FP, FN, TP = extract_conf_matrix(x)\n",
    "    return TP/(TP+FN+FP)\n",
    "\n",
    "def ACC(x):\n",
    "    TN, FP, FN, TP = extract_conf_matrix(x)\n",
    "    return (TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "def BA(x):\n",
    "    return (TPR(x)+TNR(x))/2\n",
    "\n",
    "def F1(x):\n",
    "    TN, FP, FN, TP = extract_conf_matrix(x)\n",
    "    return (2*TP)/(2*TP+FP+FN)\n",
    "\n",
    "def MCC(x):\n",
    "    TN, FP, FN, TP = extract_conf_matrix(x)\n",
    "    t = TP*TN-FP*FN\n",
    "    n = sqrt(float((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)))\n",
    "    \n",
    "def FM(x):\n",
    "    return sqrt(PPV(x)*TPR(x))\n",
    "\n",
    "def BM(x):\n",
    "    return TPR(x)+TNR(x)-1\n",
    "\n",
    "def MK(x):\n",
    "    return PPV(x)+NPV(x)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11fcc3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, name, vmax=255):\n",
    "    ''' This helper function makes displaying gray scale images easier'''\n",
    "    plt.imshow(img, cmap='gray', vmin = 0, vmax = vmax,interpolation='none')\n",
    "    plt.title(name)\n",
    "    plt.show()\n",
    "    \n",
    "def thresholding(image, threshold):\n",
    "    '''This helper function makes thresholding easier'''\n",
    "    # Thresholding\n",
    "    thresh_image = image.copy()\n",
    "    thresh_image[image>=threshold]=1\n",
    "    thresh_image[image<threshold]=0\n",
    "    return thresh_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2afac8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the name of the algorithm you would like to evalutate (case sensitive)farid\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'farid_measures.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-438bb5cbcc49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0medge_algorithm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please input the name of the algorithm you would like to evalutate (case sensitive)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{edge_algorithm}_measures.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{edge_algorithm} confusion matrices'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Drop columns with no confusion matrixes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'^Unnamed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'farid_measures.csv'"
     ]
    }
   ],
   "source": [
    "edge_algorithm = input('Please input the name of the algorithm you would like to evalutate (case sensitive)')\n",
    "df = pd.read_csv(f'{edge_algorithm}_measures.csv')\n",
    "print(f'{edge_algorithm} confusion matrices')\n",
    "# Drop columns with no confusion matrixes\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Image number name')]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58d86cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_measurements(edge_algorithm, measurement):\n",
    "    ''' Helps return a DataFrame with the values caluated with the input measurement\n",
    "    '''\n",
    "    df = pd.read_csv(f'{edge_algorithm}_measures.csv')\n",
    "\n",
    "    # Drop columns with no confusion matrixes\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    df = df.loc[:, ~df.columns.str.contains('Image number name')]\n",
    "    return df.apply(np.vectorize(measurement))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e7287b",
   "metadata": {},
   "source": [
    "# Plot precision recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb93ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pr_algorithms(list_algorithms, f_scores = [0.01, 0.1, 0.2, 0.4, 0.6, 0.8]):\n",
    "    # setup plot details\n",
    "    plt.figure(figsize=(7, 8))\n",
    "    max_x = 0\n",
    "    max_y = 0\n",
    "    for edge_detector in list_algorithms:\n",
    "        df_temp_PPV = create_measurements(edge_detector, PPV)\n",
    "        df_temp_TPR = create_measurements(edge_detector, TPR)\n",
    "        \n",
    "        # Plot for edge detector\n",
    "        recall_list = [np.mean(df_temp_TPR[column]) for column in df_temp_TPR] # recall_list\n",
    "        precision_list = [np.mean(df_temp_PPV[column]) for column in df_temp_PPV] # precision_list\n",
    "        plt.plot(recall_list, precision_list, \n",
    "                 label=f'{edge_detector}')\n",
    "        \n",
    "        # update max for good fit Iso-F1\n",
    "        if np.max(recall_list) > max_x:\n",
    "            max_x = np.max(recall_list)\n",
    "        if np.max(precision_list) > max_y:\n",
    "            max_y = np.max(precision_list)\n",
    "            \n",
    "        # Show progress\n",
    "        print(f'{edge_detector} done', end=\"\")\n",
    "        \n",
    "    # Plot Iso-F1\n",
    "    for f_score in f_scores:\n",
    "        x = np.linspace(0.01, 1)\n",
    "        y = f_score * x / (2 * x - f_score)\n",
    "        l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n",
    "        plt.annotate(f'f1={f_score}', xy=(0.9, y[45] + 0.02))\n",
    "    \n",
    "    plt.xlim(0,max_x)\n",
    "    plt.ylim(0,max_y)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "## This was my original ROC implementation\n",
    "def plot_ROC_algorithms(list_algorithms, pretty_names, f_scores = [0.01, 0.1, 0.2, 0.4, 0.6, 0.8]):\n",
    "    auc_dict = dict()\n",
    "    \n",
    "    # setup plot details\n",
    "    plt.figure(figsize=(7, 8))\n",
    "    \n",
    "    for edge_detector, pretty_name in zip(list_algorithms, pretty_names):\n",
    "        df_temp_FPR = create_measurements(edge_detector, FPR) # x fall-out or false positive rate (FPR)\n",
    "        df_temp_TPR = create_measurements(edge_detector, TPR) # y sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "        \n",
    "        \n",
    "        # Plot for edge detector\n",
    "        FPR_list = [np.mean(df_temp_FPR[column]) for column in df_temp_FPR] # x\n",
    "        TPR_list = [np.mean(df_temp_TPR[column]) for column in df_temp_TPR] # y\n",
    "        \n",
    "        temp_auc_val = auc(FPR_list, TPR_list)\n",
    "        plt.plot(FPR_list, TPR_list, label=f'{pretty_name}, AUC: {temp_auc_val:.4f}')\n",
    "        auc_dict[edge_detector] = temp_auc_val\n",
    "        print(f'{pretty_name} is done, AUC={temp_auc_val}', end=\", \")\n",
    "    \n",
    "\n",
    "    plt.xlabel('False positives')\n",
    "    plt.ylabel('True positives')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return auc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4656d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the names of all the edge detector you would like to evaluate\n",
    "# list_algorithms = ['farid']\n",
    "# plot_pr_algorithms(list_algorithms) # UNCOMMENT TO USE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9a2bd6",
   "metadata": {},
   "source": [
    "# Precision recall curves\n",
    "To plot the precision recall curves for your edge detection methods you should have the .csv files for every one of them. The names of the edge detectors should be added to the variable ```all_edge_detectors```. An example is shown below:\n",
    "```python\n",
    "all_edge_detectors = ['frei', 'prewitt', 'scharr', 'sobel', 'farid', 'roberts', 'gabor_filterbank1', 'GS3O11', 'GS5O11', 'GS5O8', 'k-means', 'canny', 'wavelet', 'LoG_sigma1.4', 'LoG_sigma2.7', 'LoG_sigma2', 'canny_sigma0.1', 'canny_sigma1', 'canny_sigma1.4', 'canny_sigma2.7']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29a76a3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot_pr_algorithms(all_edge_detectors) # ADD OWN EDGE DETECTOR NAMES AND UNCOMMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feac82d",
   "metadata": {},
   "source": [
    "# ROC curves\n",
    "For the creation of the ROC curves, the names of the edge detectors in the .csv filenames should be added to ```edge_detectors_without_params```. These names might not containt capitals or some basic explaination. Therefore add the names you would like to display in the legend of the ROC curves to the ```edge_detectors_without_params_pretty``` variable in a list. An example is shown below:\n",
    "```python\n",
    "edge_detectors_without_params = ['farid','frei','prewitt','roberts', 'scharr','sobel','wavelet']\n",
    "edge_detectors_without_params_pretty = ['Farid','Frei-Chen','Prewitt','Roberts','Scharr','Sobel','Wavelet']\n",
    "auc_dict_no_params = plot_ROC_algorithms(edge_detectors_without_params, edge_detectors_without_params_pretty)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "239080d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc_dict_no_params = plot_ROC_algorithms(edge_detectors_without_params, edge_detectors_without_params_pretty) # ADD OWN EDGE DETECTOR NAMES AND UNCOMMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7db927",
   "metadata": {},
   "source": [
    "# Evaluation of other metrics\n",
    "To create a DataFrame with metrics, for example F1 score. The ```create_measurements``` definition can be used. This definition will return the DataFrame with the given metric for every threshold and image. An example of the code is shown below:\n",
    "```python\n",
    "print(f'F1 values for {edge_algorithm}')\n",
    "df_F1 = create_measurements(edge_algorithm, F1)\n",
    "df_F1\n",
    "```\n",
    "\n",
    "With this dataframe, averages, maximum values etc. can "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
